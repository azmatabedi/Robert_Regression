{"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"yDDYzvzBB-Wr","executionInfo":{"status":"ok","timestamp":1644047877602,"user_tz":-300,"elapsed":648,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["import pandas as pd \n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hyPXHwuUCGWa","executionInfo":{"status":"ok","timestamp":1644047878186,"user_tz":-300,"elapsed":4,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["from google.colab import drive\n","#drive.mount('/content/gdrive/', force_remount=True)\n","\n","isLocation = False\n","\n","# path = '/content/gdrive/MyDrive/GTD/data_til_2010.csv'\n","# path = '/content/gdrive/MyDrive/GTD/data_1970_80.csv'\n","# path = '/content/gdrive/MyDrive/GTD/data_1981_95.csv'\n","# path = '/content/gdrive/MyDrive/GTD/data_96_2010.csv'\n","# path = '/content/gdrive/MyDrive/GTD/data_2011_12.csv'\n","# path = '/content/gdrive/MyDrive/GTD/data_2013_14.csv'\n","#path = '/content/gdrive/MyDrive/GTD/data_2015_17.csv'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hkhc10wNrGt","outputId":"8edf552d-d1db-431f-d5b7-c3dbdbf28b89","executionInfo":{"status":"ok","timestamp":1644047881278,"user_tz":-300,"elapsed":3095,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"j2qGe5eCCbHa","executionInfo":{"status":"ok","timestamp":1644047881279,"user_tz":-300,"elapsed":6,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["\n","def get_preprocess_data(originData):\n","  # originData = originData.rename(index=str, columns={'event id': 'eventid'})\n","  df = originData[originData['city'].notnull()] \n","  # print(\"Columns before prepprocessing\",len(df.columns))\n","  #df = df.loc[:,df.isnull().sum()/len(df) <0.30]\n","  # print(\"Columns after prepprocessing\",len(df.columns))\n","  categorical = ['extended','crit1','crit2','crit3','doubtterr','alternative','alternative_txt','multiple','enc_country',\\\n","               'country_txt','enc_region','region_txt','vicinity','specificity','enc_attacktype','attacktype','enc_weapon_type',\\\n","               'weapon_type','enc_weapon_subtype','weapon_subtype','success','suicide','target_entity','enc_target','target_type',\n","               'target_subtype','enc_nationality','nationality','claimed','property','cross_border','ideological_international',\\\n","               'province','entity','group','hostages/kidnapping','city','INT_MISC','INT_ANY','individual']\n","  \n","\n","  df.rename(columns = {'iyear':'year','imonth':'month','iday':'day','region':'enc_region',\\\n","                     'attacktype1_txt':'attacktype','attacktype1':'enc_attacktype',\\\n","                     'provstate':'province','country':'enc_country',\\\n","                     'targtype1_txt':'target_type','targtype1':'enc_target',\\\n","                     'targsubtype1_txt':'target_subtype',\\\n","                     'target1':'target_entity','weaptype1':'enc_weapon_type',\\\n","                     'weaptype1_txt':'weapon_type','weapsubtype1_txt':'weapon_subtype','weapsubtype1':'enc_weapon_subtype',\\\n","                     'corp1':'entity','natlty1':'enc_nationality','natlty1_txt':'nationality',\\\n","                     'gname':'group','nkill':'killed','nwound':'wounded',\\\n","                     'targsubtype':'enc_target_subtype',\\\n","                     'ishostkid':'hostages/kidnapping','INT_LOG':'cross_border',\\\n","                     'INT_IDEO':'ideological_international'}, inplace = True)\n","  for item in categorical:\n","    if item not in df.columns:\n","        pass\n","    else:\n","        df[item] = df[item].astype('category')\n","\n","\n","  \n","\n","  #df[\"enc_city\"] = df[\"city\"].cat.codes\n","  # df[\"country_txt\"] = df[\"country_txt\"].cat.codes\n","  # df[\"region_txt\"] = df[\"region_txt\"].cat.codes\n","  # df[\"enc_group\"] = df[\"group\"].cat.codes\n","  if isLocation:\n","    df1 = df[[\"killed\", \"scite1\"]]\n","    df1 = df1.dropna()\n","    df1.rename(columns = {'killed':'label','scite1': 'text'},inplace = True)\n","\n","  else:\n","    df[\"enc_group\"] = df[\"group\"].cat.codes\n","    df1 = df[[\"enc_group\", \"scite1\"]]\n","    df1 = df1.dropna()\n","    df1.rename(columns = {'enc_group':'label','scite1': 'text'},inplace = True)\n","\n","  # df['Date'] = pd.to_datetime(df[['year','month','day']], errors = 'coerce')\n","  # df['occurDate'] = df['Date'].apply(lambda x: pd.Timestamp(x).date())\n","  # df = df.drop(columns = ['Date','year','month','day','extended','country_txt','province','city','latitude','longitude','crit1','crit2','crit3',\n","  #              'attacktype','target_type','target_subtype','target_entity','nationality','group','weapon_type','weapon_subtype','dbsource'\n","  #              ,'property','hostages/kidnapping','cross_border','ideological_international','INT_MISC'])\n","  # print(df1)\n","  return df1"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"x4giRzM7NtHJ","executionInfo":{"status":"ok","timestamp":1644047881824,"user_tz":-300,"elapsed":550,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# specify GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device = torch.device(\"cuda\")"]},{"cell_type":"code","source":["import chardet\n","file=\"/content/data_96_2010.csv\"\n","with open(file, 'rb') as rawdata:\n","    result = chardet.detect(rawdata.read(100000))\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5CGC1t_RfOcg","executionInfo":{"status":"ok","timestamp":1644047882239,"user_tz":-300,"elapsed":416,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}},"outputId":"d4d1e70e-8d3d-4357-cb7a-ed8fc50e686d"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'confidence': 0.73, 'encoding': 'ISO-8859-1', 'language': ''}"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"kKd-Tj3hOMsZ"},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwJrQFQgN_BE","outputId":"b16ea50a-9ddd-46a8-96d6-5efcb3d752df","executionInfo":{"status":"ok","timestamp":1644047883620,"user_tz":-300,"elapsed":1382,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (33,62,63,76,79,94,96,114,115) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["895\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}],"source":["# df = pd.read_csv(\"spamdata_v2.csv\")\n","# df.head()\n","\n","#path = '/content/data_96_2010.csv'\n","\n","originData = pd.read_csv(file,encoding = \"ISO-8859-1\")\n","df = get_preprocess_data(originData)\n","\n","\n","print(len(df.label.unique()))\n","\n","n_classes = len(df.label.unique())"]},{"cell_type":"code","source":["df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfvOOg7Wnwkq","outputId":"337e7946-7c36-4297-9c12-ba0f594de6ac","executionInfo":{"status":"ok","timestamp":1644047883620,"user_tz":-300,"elapsed":13,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['label', 'text'], dtype='object')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYBid8NLkvRm","outputId":"76a805e1-c0d1-4359-f104-0befcbf66143","executionInfo":{"status":"ok","timestamp":1644047883621,"user_tz":-300,"elapsed":11,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1105"]},"metadata":{},"execution_count":9}],"source":["max(np.unique(df.label))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzPPOrVQWiW5","outputId":"77503fd5-841d-4201-e2bf-55ca1d9ec71b","executionInfo":{"status":"ok","timestamp":1644047883621,"user_tz":-300,"elapsed":10,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(31800, 2)"]},"metadata":{},"execution_count":10}],"source":["df.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"676DPU1BOPdp","outputId":"7c574d3e-393e-4e07-8a89-9a68be9c4468","executionInfo":{"status":"ok","timestamp":1644047883622,"user_tz":-300,"elapsed":10,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1072    0.555786\n","973     0.043176\n","273     0.032956\n","856     0.025283\n","604     0.020786\n","          ...   \n","737     0.000031\n","281     0.000031\n","343     0.000031\n","312     0.000031\n","101     0.000031\n","Name: label, Length: 895, dtype: float64"]},"metadata":{},"execution_count":11}],"source":["# check class distribution\n","df['label'].value_counts(normalize = True)"]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"mfhSPF5jOWb7","executionInfo":{"status":"ok","timestamp":1644047883622,"user_tz":-300,"elapsed":8,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n","                                                                    random_state=2018, \n","                                                                    test_size=0.3)\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","                                                                random_state=2018, \n","                                                                test_size=0.5)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OEN63vtANj9b","outputId":"cdd29330-5bf6-4d29-ef0c-3ae3873cf690","executionInfo":{"status":"ok","timestamp":1644047883623,"user_tz":-300,"elapsed":9,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["22260\n"]}],"source":["print(len(train_labels))"]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"S1kY3gZjO2RE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644047888073,"user_tz":-300,"elapsed":4457,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}},"outputId":"3dd28dcd-e806-4ea8-af12-7e24b786e91c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# import BERT-base pretrained model\n","bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# # Load the BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Jf9Q-V6a2Xqd","executionInfo":{"status":"ok","timestamp":1644047888075,"user_tz":-300,"elapsed":14,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["\n","#from transformers import RobertaTokenizer,RobertaModel\n","\n","#bert = RobertaModel.from_pretrained('roberta-base')\n","#tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"_zOKeOMeO-DT","executionInfo":{"status":"ok","timestamp":1644047888075,"user_tz":-300,"elapsed":13,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAH73n39PHLw","outputId":"97cc169e-85d3-4663-bb0d-142e314df467","executionInfo":{"status":"ok","timestamp":1644047888075,"user_tz":-300,"elapsed":13,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}],"source":["# output\n","print(sent_id)"]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"yKwbpeN_PMiu","outputId":"fa1a88fd-c9b0-4f54-d710-6b01a28fc2e5","executionInfo":{"status":"ok","timestamp":1644047888076,"user_tz":-300,"elapsed":13,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fb775eaefd0>"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# get length of all the messages in the train set\n","seq_len = [len(i.split()) for i in train_text]\n","\n","pd.Series(seq_len).hist(bins = 10)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"OXcswEIRPvGe","executionInfo":{"status":"ok","timestamp":1644047888076,"user_tz":-300,"elapsed":9,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["max_seq_len = 100"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tk5S7DWaP2t6","outputId":"7aeff196-2cc3-41f8-eaab-4ed1bfda4739","executionInfo":{"status":"ok","timestamp":1644047891907,"user_tz":-300,"elapsed":3840,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"QR-lXwmzQPd6","executionInfo":{"status":"ok","timestamp":1644047891907,"user_tz":-300,"elapsed":7,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiiZ42B2Q8w6","outputId":"6d2e64ac-a1fb-4afa-9632-e95c3e1da8f1","executionInfo":{"status":"ok","timestamp":1644047891908,"user_tz":-300,"elapsed":7,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["22260\n"]}],"source":["print(len(train_y))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0e4_DZ_IssrF","outputId":"7858d88d-490a-414c-fa27-f17b9e8dddee","executionInfo":{"status":"ok","timestamp":1644047892469,"user_tz":-300,"elapsed":567,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["895\n"]}],"source":["print(len(df.label.unique()))"]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"qUy9JKFYQYLp","executionInfo":{"status":"ok","timestamp":1644047892469,"user_tz":-300,"elapsed":3,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 690 #int(max(df.label.unique()))\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["+\n","# Freeze BERT Parameters"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"wHZ0MC00RQA_","executionInfo":{"status":"ok","timestamp":1644047892469,"user_tz":-300,"elapsed":2,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"b3iEtGyYRd0A","executionInfo":{"status":"ok","timestamp":1644047892469,"user_tz":-300,"elapsed":2,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      self.fc1 = nn.Linear(768,512)\n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(512,int(max(df.label))+1) #int(max(df.label.unique())))\n","\n","      #softmax activation function\n","      #self.softmax = nn.LogSoftmax(dim=1)\n","      self.tanh1 = nn.Tanh()\n","      self.ff2 = nn.Linear(int(max(df.label))+1,1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n","      \n","      x = self.fc1(cls_hs)\n","\n","      x = self.relu(x)\n","\n","      x = self.dropout(x)\n","\n","      # output layer\n","      x = self.fc2(x)\n","      \n","      # apply softmax activation\n","      # x = self.softmax(x)\n","\n","      x = self.tanh1(x)\n","      x = self.ff2(x)\n","      return x"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"kK2iTuTxtbsa","executionInfo":{"status":"ok","timestamp":1644047892470,"user_tz":-300,"elapsed":3,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":27,"metadata":{"id":"cBAJJVuJRliv","executionInfo":{"status":"ok","timestamp":1644047898713,"user_tz":-300,"elapsed":6246,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"taXS0IilRn9J","executionInfo":{"status":"ok","timestamp":1644047903401,"user_tz":-300,"elapsed":4696,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["from transformers.utils.dummy_pt_objects import Adafactor\n","# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = Adafactor(model.parameters(), lr = 1e-3)"]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"izY5xH5eR7Ur","executionInfo":{"status":"ok","timestamp":1644047952006,"user_tz":-300,"elapsed":338,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight(class_weight = None, classes= np.unique(df.label),y= train_labels)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"wM5ygwTsSVEl","executionInfo":{"status":"ok","timestamp":1644047949804,"user_tz":-300,"elapsed":336,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["class_wts = np.ones(2)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llTO8EXh6BwE","outputId":"c264d558-09a0-4bb2-af6a-f07ca581a325","executionInfo":{"status":"ok","timestamp":1644047903402,"user_tz":-300,"elapsed":14,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}],"source":["print(len(class_wts))"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"r1WvfY2vSGKi","executionInfo":{"status":"ok","timestamp":1644047903402,"user_tz":-300,"elapsed":13,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","# cross_entropy  = nn.NLLLoss(weight=weights)\n","\n","cross_entropy  = torch.nn.L1Loss()\n","\n","# number of training epochs\n","epochs = 10"]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"rskLk8R_SahS","executionInfo":{"status":"ok","timestamp":1644047955471,"user_tz":-300,"elapsed":352,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    # print(\"preds\",preds.shape)\n","    # print(\"labels\",labels.shape)\n","    labels = labels.to(device,dtype=torch.long)\n","    # preds = preds.to(device,dtype=torch.long)\n","    loss = cross_entropy(preds, labels)\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"yGXovFDlSxB5","executionInfo":{"status":"ok","timestamp":1644047903403,"user_tz":-300,"elapsed":13,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"id":"k1USGTntS3TS","outputId":"156273b0-717b-4af8-fc91-2ed14433179d","executionInfo":{"status":"error","timestamp":1644047928740,"user_tz":-300,"elapsed":376,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Epoch 1 / 10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([690])) that is different to the input size (torch.Size([690, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-c5138ddf6b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-8429c8386ccf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# preds = preds.to(device,dtype=torch.long)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# add on to the total loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2165\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Long for argument #2 'target'"]}],"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OacxUyizS8d1","executionInfo":{"status":"aborted","timestamp":1644047905214,"user_tz":-300,"elapsed":483,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["#load weights of best model\n","path1 = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path1))"]},{"cell_type":"code","source":["train_losses=[]\n","valid_losses=[]"],"metadata":{"id":"Fp7byFrRRMtG","executionInfo":{"status":"aborted","timestamp":1644047905216,"user_tz":-300,"elapsed":485,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch"],"metadata":{"id":"S6yVkCyCwBbv","executionInfo":{"status":"aborted","timestamp":1644047905217,"user_tz":-300,"elapsed":486,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STZNC-X01adG","executionInfo":{"status":"ok","timestamp":1644047914352,"user_tz":-300,"elapsed":3175,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}},"outputId":"a856dbd8-d53d-4004-8814-bfb06e433fa1"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Requirement already satisfied: torch==1.2.0+cu92 in /usr/local/lib/python3.7/dist-packages (1.2.0+cu92)\n","Requirement already satisfied: torchvision==0.4.0+cu92 in /usr/local/lib/python3.7/dist-packages (0.4.0+cu92)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0+cu92) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (7.1.2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"NZl0SZmFTRQA","colab":{"base_uri":"https://localhost:8080/","height":380},"outputId":"0ebc0844-abc1-4cef-8f6c-befb37ea4b89","executionInfo":{"status":"error","timestamp":1644048234019,"user_tz":-300,"elapsed":2178,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-4a648a6a52df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-1475896819b0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2438\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mgelu_python\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mGaussian\u001b[0m \u001b[0mError\u001b[0m \u001b[0mLinear\u001b[0m \u001b[0mUnits\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 5.46 GiB (GPU 0; 14.76 GiB total capacity; 8.62 GiB already allocated; 5.24 GiB free; 36.18 MiB cached)"]}],"source":["# get predictions for test data\n","import torch\n","torch.cuda.empty_cache()\n","import gc\n","\n","gc.collect()\n","\n","torch.cuda.empty_cache()\n","with torch.no_grad():\n","  preds = model(test_seq.to(device), test_mask.to(device))\n","  preds = preds.detach().cpu().numpy()"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"-ZOHjEaPcm-x","executionInfo":{"status":"aborted","timestamp":1644047905221,"user_tz":-300,"elapsed":490,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Accuracy metrics\n","def forecast_accuracy(forecast, actual):\n","    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n","    me = np.mean(forecast - actual)             # ME\n","    mae = np.mean(np.abs(forecast - actual))    # MAE\n","    mpe = np.mean((forecast - actual)/actual)   # MPE\n","    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n","    # corr = np.corrcoef(forecast, actual)[0,1]   # corr\n","    # mins = np.amin(np.hstack([forecast[:,None], \n","    #                           actual[:,None]]), axis=1)\n","    # maxs = np.amax(np.hstack([forecast[:,None], \n","    #                           actual[:,None]]), axis=1)\n","    # minmax = 1 - np.mean(mins/maxs)             # minmax\n","    # acf1 = acf(fc-test)[1]                      # ACF1\n","    return({'mape':mape, 'me':me, 'mae': mae, \n","            'mpe': mpe, 'rmse':rmse})\n","\n"],"metadata":{"id":"egtEppWWbOep","executionInfo":{"status":"aborted","timestamp":1644047905221,"user_tz":-300,"elapsed":490,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(test_y)"],"metadata":{"id":"gupKw2ibVX8U","executionInfo":{"status":"aborted","timestamp":1644047905222,"user_tz":-300,"elapsed":491,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(preds)"],"metadata":{"id":"hB4xAN7ndyyI","executionInfo":{"status":"aborted","timestamp":1644047905223,"user_tz":-300,"elapsed":492,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms1ObHZxTYSI","executionInfo":{"status":"aborted","timestamp":1644047905223,"user_tz":-300,"elapsed":492,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# model's performance\n","# preds = np.argmax(preds, axis = 1)\n","print(forecast_accuracy(test_y.numpy(), preds))\n","\n","# if isLocation:\n","#   print(\"City/Location\")\n","  \n","# else:\n","#   print(\"group_name\")\n","\n","print(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqzLS7rHTp4T","executionInfo":{"status":"aborted","timestamp":1644047905224,"user_tz":-300,"elapsed":493,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":["# confusion matrix\n","# pd.crosstab(test_y, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpX1uTwjUPY6","executionInfo":{"status":"aborted","timestamp":1644047905225,"user_tz":-300,"elapsed":494,"user":{"displayName":"Scientist Azmat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMLKYDh84trLpXfrO-Z5VnzwoMS36ssgIKVMKpxg=s64","userId":"05254092664975896905"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["MKfWnApvOoE7"],"name":"GTD_RoBERTA_Regression.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}